{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c5848f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change tabula to tabula_middle_padding to test middle padding method\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from tabula_middle_padding import Tabula \n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e438a14b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/drive1/zhd/Tabula/Real_Datasets/Covertype_compressed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f700ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'income']\n",
    "model = Tabula(llm='distilgpt2', experiment_dir = \"covertype_training\", batch_size=32, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a817f703-581d-42a8-aed9-681639a02ea9",
   "metadata": {},
   "source": [
    "## In following block, it is important to indicate \"conditional_col = data.columns[0]\". Otherwise, the generation will use target column as conditional column, which will result in error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "837b11c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditional_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/drive1/zhd/Tabula/tabula_middle_padding/tabula.py:105\u001b[0m, in \u001b[0;36mTabula.fit\u001b[0;34m(self, data, column_names, conditional_col, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    103\u001b[0m         encoded_term \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mstr\u001b[39m(data[var][i])\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mindex]\n\u001b[1;32m    104\u001b[0m         token_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(encoded_term)\n\u001b[0;32m--> 105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_list_length\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtoken_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m    108\u001b[0m df \u001b[38;5;241m=\u001b[39m _array_to_dataframe(data, columns\u001b[38;5;241m=\u001b[39mcolumn_names)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_column_information(df)\n",
      "File \u001b[0;32m~/anaconda3/envs/tabula/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:267\u001b[0m, in \u001b[0;36mBatchEncoding.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    `bool`: Indicate whether this [`BatchEncoding`] was generated from the result of a [`PreTrainedTokenizerFast`]\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    or not.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Any, EncodingFast]:\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    If the key is a string, returns the value of the dict associated to `key` ('input_ids', 'attention_mask',\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m    etc.).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m    with the constraint of slice.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(data, conditional_col = data.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model.model.state_dict(), \"covertype_training/model_30epoch.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b743035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6094it [00:23, 260.83it/s]                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "synthetic_data = model.sample(n_samples=50000, max_length=200)\n",
    "synthetic_data.to_csv(\"covertype_30epoch.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f2b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabula",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
