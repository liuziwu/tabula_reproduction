{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c5848f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change tabula to tabula_middle_padding to test middle padding method\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\" \n",
    "from tabula import Tabula \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f7b266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集所有列名： ['duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'label']\n",
      "列 protocol_type 类型：object\n",
      "列 service 类型：object\n",
      "列 flag 类型：object\n",
      "列 land 类型：object\n",
      "列 wrong_fragment 类型：object\n",
      "列 urgent 类型：object\n",
      "列 hot 类型：object\n",
      "列 num_failed_logins 类型：object\n",
      "列 logged_in 类型：object\n",
      "列 num_compromised 类型：object\n",
      "列 root_shell 类型：object\n",
      "列 su_attempted 类型：object\n",
      "列 num_root 类型：object\n",
      "列 num_file_creations 类型：object\n",
      "列 num_shells 类型：object\n",
      "列 num_access_files 类型：object\n",
      "列 num_outbound_cmds 类型：object\n",
      "列 is_host_login 类型：object\n",
      "列 is_guest_login 类型：object\n",
      "列 label 类型：object\n",
      "最终分类列数量： 20\n",
      "最终分类列列表： ['protocol_type', 'service', 'flag', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'label']\n"
     ]
    }
   ],
   "source": [
    "# 步骤1：加载数据并确认列名完全匹配\n",
    "data = pd.read_csv(\"Real_Datasets/Intrusion_compressed.csv\")\n",
    "# 打印所有列名，核对分类列列表的拼写\n",
    "print(\"数据集所有列名：\", data.columns.tolist())\n",
    "\n",
    "# 步骤2：定义完全匹配的分类列列表（逐列核对后修正）\n",
    "categorical_columns = [\n",
    "    \"protocol_type\", \"service\", \"flag\", \"land\", \"wrong_fragment\", \"urgent\",\n",
    "    \"hot\", \"num_failed_logins\", \"logged_in\", \"num_compromised\", \"root_shell\",\n",
    "    \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\",\n",
    "    \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\",\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "# 步骤3：强制转换分类列类型（每次加载后必执行）\n",
    "for col in categorical_columns:\n",
    "    data[col] = data[col].astype(\"object\")\n",
    "    print(f\"列 {col} 类型：{data[col].dtype}\")  # 验证转换是否成功\n",
    "\n",
    "# 步骤4：验证分类列数量\n",
    "new_cat_cols = data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(\"最终分类列数量：\", len(new_cat_cols))  # 应输出21\n",
    "print(\"最终分类列列表：\", new_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f700ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 指定分类列（20个特征列+1个标签列，共21个）\n",
    "categorical_columns = [\n",
    "    \"protocol_type\", \"service\", \"flag\", \"land\", \"logged_in\", \"is_host_login\",\n",
    "    \"is_guest_login\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"label\"\n",
    "]\n",
    "\n",
    "# 2. 初始化模型（关键参数：epochs=50，大数据集LLM训练标准；batch_size=32，内存不足可改为16）\n",
    "model = Tabula(\n",
    "    llm='distilgpt2', \n",
    "    experiment_dir=\"intrusion_training\", \n",
    "    batch_size=32, \n",
    "    epochs=50,  # 文档要求“大数据集训练50个epoch”\n",
    "    categorical_columns=categorical_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43f166f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comment this block out to test tabula starting from randomly initialized model.\n",
    "# Comment this block out when uses tabula_middle_padding\n",
    "import torch\n",
    "model.model.load_state_dict(torch.load(\"pretrained-model/tabula_pretrained_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b11c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/drive1/zhd/Tabula/tabula/tabula.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `TabulaTrainer.__init__`. Use `processing_class` instead.\n",
      "  tabula_trainer = TabulaTrainer(self.model, training_args, train_dataset=tabula_ds, tokenizer=self.tokenizer,\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19892' max='78150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19892/78150 2:36:04 < 7:37:09, 2.12 it/s, Epoch 12.73/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.385500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.375500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.377900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.377300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.376900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.375900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.375400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.375200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.374900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.374700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.374400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.374500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.373500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.373900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.373100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.373200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.372600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.373100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.372600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.372500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.371900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.372600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.371900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.371700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.371800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.371300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.371600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.371700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.371400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d3e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 保存训练后的模型\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#torch.save(model.model.state_dict(), \"intrusion_training/model_50epoch.pt\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 生成合成数据（max_length=200，覆盖Intrusion的token长度；n_samples=50000匹配原始数据量）\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m synthetic_data \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m synthetic_data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintrusion_50epoch.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 多分类F1-score评估（参考文档Tabula结果：0.981±0.002）\u001b[39;00m\n",
      "File \u001b[0;32m/drive1/zhd/Tabula/tabula/tabula.py:201\u001b[0m, in \u001b[0;36mTabula.sample\u001b[0;34m(self, n_samples, start_col, start_col_dist, temperature, k, max_length, device)\u001b[0m\n\u001b[1;32m    199\u001b[0m already_generated \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_samples \u001b[38;5;241m>\u001b[39m df_gen\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 201\u001b[0m     start_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtabula_start\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_start_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     start_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(start_tokens)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# Generate tokens\u001b[39;00m\n",
      "File \u001b[0;32m/drive1/zhd/Tabula/tabula/tabula_start.py:153\u001b[0m, in \u001b[0;36mRandomStart.get_start_tokens\u001b[0;34m(self, n_samples)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_start_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_samples):\n\u001b[0;32m--> 153\u001b[0m     start_words \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     start_text \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m start_words]\n\u001b[1;32m    155\u001b[0m     start_tokens \u001b[38;5;241m=\u001b[39m _pad_tokens(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(start_text)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/tabula/lib/python3.10/random.py:514\u001b[0m, in \u001b[0;36mRandom.choices\u001b[0;34m(self, population, weights, cum_weights, k)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a k sized list of population elements chosen with replacement.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03mIf the relative weights or cumulative weights are not specified,\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03mthe selections are made with equal probability.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m random \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\n\u001b[0;32m--> 514\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cum_weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "# 保存训练后的模型\n",
    "torch.save(model.model.state_dict(), \"intrusion_training/model_50epoch.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b743035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成合成数据（max_length=200，覆盖Intrusion的token长度；n_samples=50000匹配原始数据量）\n",
    "synthetic_data = model.sample(n_samples=50000, max_length=200)\n",
    "synthetic_data.to_csv(\"intrusion_50epoch.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f2b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabula",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
